# 어제 복습
# I/O = Input & Output
# RAG, Agent

# Agent를 쓰지 않았을 때는 모른다고 대답했던 답변에서 wikipedia를 에이전트로 건네줬더니 AI 스스로 위키피디아를 이용해 해당 검색 결과를 불러옴

# Retrieval
# 1. Indexing Phase
# document생성
from langchain_community.document_loaders import PyPDFLoader

loader = PyPDFLoader('./snow-white.pdf')
documents = loader.load()

for doc in documents:
    doc.page_content = doc.page_content.replace('\n', ' ')
    # doc.page_content만 했을 때의 예시
    # \n왕비는 진실만을 말하는 요술 거울에게 늘 이렇게 물\n었어요.\n“거울아, 거울아. 이 세상에서 누가 가장 아름답니?”\n 
    # \n 개행문자를 공백 혹은 빈 문자열로 replace
documents    

# Text Splitter
# RecursiveCharacterTextSplitter : 긴 텍스트를 재귀적으로 분석하여 작은 조각으로 분할하는 TextSplitter의 구현체

from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    # 글자 수 몇 개를 기준으로 해서 쪼갤거냐(보통은 1000을 기준으로 함)
    chunk_size=100,
    # 문단 단위로 쪼개온다고 할 때, 유실이 될 수도 있음. 그래서 문단 앞 뒤를 살짝 겹치게 쪼개와야한다.
    # chunk_overlap=겹칠 글자 수
    chunk_overlap=20
)
docs = splitter.split_documents(documents)
print(len(docs))  # 26
docs



# 오늘 수업
# 임베딩 모델(어제 한 결과물 벡터화)
1. 임베딩 모델 사용 위해 필요 요소 import
from langchain_openai.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    # vector store가 알아서 임베딩 모델을 저장해줌
)

2. 벡터 스토어 사용 위해 필요 요소 install
%pip install langchain-chroma

from langchain_chroma.vectorstores import Chroma

3. Retrival 기반, 유사도 검색
from langchain_chroma.vectorstores import Chroma

vector_store = Chroma.from_documents(docs, embeddings)

query = '백설공주와 왕비 중에 누가 더 아름다운가요?'

# retrieval 사용 않고 벡터 스토어에 직접 조회하는 방법도 있다.
# similarity_search 사용
retrievals = vector_store.similarity_search_with_score(query)
retrievals

"""
[(Document(id='82f069db-d2ed-4bd5-80d4-1a2896cb70a3', metadata={'title': 'PowerPoint 프레젠테이션', 'page': 2, 'creationdate': '2023-09-12T11:20:24+09:00', 'author': 'PC', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'total_pages': 6, 'page_label': '3', 'source': './snow-white.pdf', 'moddate': '2023-09-12T11:20:24+09:00'}, page_content='왕비는 다시 요술 거울에게 누가 가장 아름다운 지 물었어요. “왕비님도 아름답지만 백설공주님이 천배는 더 아름답습니다.” “사냥꾼이 날 속였구나. 내가 직접 해치우겠어!”'),
  0.8201914429664612),
 (Document(id='d4d6b554-966b-47d4-9b79-351ec27c9054', metadata={'title': 'PowerPoint 프레젠테이션', 'producer': 'Microsoft® PowerPoint® 2013', 'total_pages': 6, 'moddate': '2023-09-12T11:20:24+09:00', 'source': './snow-white.pdf', 'creator': 'Microsoft® PowerPoint® 2013', 'creationdate': '2023-09-12T11:20:24+09:00', 'page_label': '2', 'page': 1, 'author': 'PC'}, page_content='거울아. 이 세상에서 누가 가장 아름답니?” “왕비님도 아름답지만 백설공주가 더 아름답습니다.” 화가 난 왕비는 사냥꾼을 불렀어요. 왕비는 사냥꾼에게 백설공주를 죽이라고'),
  0.8282550573348999),
 (Document(id='629c8c18-4130-4dd0-bab2-ea99ca174668', metadata={'total_pages': 6, 'author': 'PC', 'source': './snow-white.pdf', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'moddate': '2023-09-12T11:20:24+09:00', 'page_label': '5', 'creationdate': '2023-09-12T11:20:24+09:00', 'page': 4, 'title': 'PowerPoint 프레젠테이션'}, page_content='“백설공주님, 못된 왕비의 꾐에 넘어갔군요.” “여전히 아름다운 우리 공주님을 캄캄한 땅속에 묻을 순 없어.” “오래오래 볼 수 있게 유리 관에 모시자.” 어느 날, 한 왕자가'),
  0.9228578209877014),
 (Document(id='980af31e-cd3a-41b8-b483-7c334da090c8', metadata={'producer': 'Microsoft® PowerPoint® 2013', 'moddate': '2023-09-12T11:20:24+09:00', 'title': 'PowerPoint 프레젠테이션', 'total_pages': 6, 'source': './snow-white.pdf', 'page_label': '2', 'creationdate': '2023-09-12T11:20:24+09:00', 'creator': 'Microsoft® PowerPoint® 2013', 'author': 'PC', 'page': 1}, page_content='왕은 아름다운 새 왕비를 맞았어요. 그런데 새 왕비는 자기보다 아름다운 사람을 두고 보 지 못했어요. 왕비는 진실만을 말하는 요술 거울에게 늘 이렇게 물 었어요. “거울아,'),
  1.043031930923462)]
"""

# Retrieval 사용 검색
retrieval = vector_store.as_retriever(
    search_tyep='similarity',
    search_kwargs={'k':3}  # kwargs = 몇 건의 결과를 원하는지
)
# vector로 검색하는 것은 키워드 기반이 아니라 '의미'기반이다.

retrievals = retrieval.batch([query]) # ([]) 리스트 안에 query 전달
retrievals

"""
[[Document(id='82f069db-d2ed-4bd5-80d4-1a2896cb70a3', metadata={'source': './snow-white.pdf', 'page_label': '3', 'author': 'PC', 'page': 2, 'creationdate': '2023-09-12T11:20:24+09:00', 'creator': 'Microsoft® PowerPoint® 2013', 'producer': 'Microsoft® PowerPoint® 2013', 'title': 'PowerPoint 프레젠테이션', 'moddate': '2023-09-12T11:20:24+09:00', 'total_pages': 6}, page_content='왕비는 다시 요술 거울에게 누가 가장 아름다운 지 물었어요. “왕비님도 아름답지만 백설공주님이 천배는 더 아름답습니다.” “사냥꾼이 날 속였구나. 내가 직접 해치우겠어!”'),
  Document(id='d4d6b554-966b-47d4-9b79-351ec27c9054', metadata={'page': 1, 'creationdate': '2023-09-12T11:20:24+09:00', 'source': './snow-white.pdf', 'page_label': '2', 'creator': 'Microsoft® PowerPoint® 2013', 'author': 'PC', 'total_pages': 6, 'title': 'PowerPoint 프레젠테이션', 'producer': 'Microsoft® PowerPoint® 2013', 'moddate': '2023-09-12T11:20:24+09:00'}, page_content='거울아. 이 세상에서 누가 가장 아름답니?” “왕비님도 아름답지만 백설공주가 더 아름답습니다.” 화가 난 왕비는 사냥꾼을 불렀어요. 왕비는 사냥꾼에게 백설공주를 죽이라고'),
  Document(id='629c8c18-4130-4dd0-bab2-ea99ca174668', metadata={'page': 4, 'creationdate': '2023-09-12T11:20:24+09:00', 'source': './snow-white.pdf', 'producer': 'Microsoft® PowerPoint® 2013', 'total_pages': 6, 'title': 'PowerPoint 프레젠테이션', 'moddate': '2023-09-12T11:20:24+09:00', 'author': 'PC', 'page_label': '5', 'creator': 'Microsoft® PowerPoint® 2013'}, page_content='“백설공주님, 못된 왕비의 꾐에 넘어갔군요.” “여전히 아름다운 우리 공주님을 캄캄한 땅속에 묻을 순 없어.” “오래오래 볼 수 있게 유리 관에 모시자.” 어느 날, 한 왕자가')]]
"""

## 2. Retrieval and Generation Phase

### 프롬프트 생성
1. 사용자 질의
2. 검색된 문서 도출

# 프롬프트 생성
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate([
    ('system', 'You are kindergarten teacher who promotes dream and hope to the kids. Answer based on context while response as much as positive when the kid asked.'),
    ('user', '''
     사용자의 질문에 context만을 이용해 답변해주세요.
     
     question: {query}

     context: {context}
    ''' )
])

prompt.invoke({'query': query, 'context':retrieval})

# system에 넣어준 페르소나가 system message로 잘 들어간 것을 확인할 수 있다.
# ChatPromptValue(messages=[SystemMessage(content='You are kindergarten teacher who promotes dream and hope to the kids. Answer based on context while response as much as positive when the kid asked.', additional_kwargs={}, response_metadata={}), HumanMessage(content="\n     사용자의 질문에 context만을 이용해 답변해주세요.\n\n     question: 백설공주와 왕비 중에 누가 더 아름다운가요?\n\n     context: tags=['Chroma', 'OpenAIEmbeddings'] vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000020ECE63FCB0> search_kwargs={'k': 3}\n    ", additional_kwargs={}, response_metadata={})])

# 모델 생성
from langchain_openai import ChatOpenAI

model = ChatOpenAI(
    model_name='gpt-4.1',
    temperature=0.5
)

# 체인 생성
# outputparser 이용
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
# RunnablePassthrough: chain 생성 후 invoke 할 때 그대로 출력할 수 있게 만든다
# (수업 노트) invoke()에 전달된 인자를 받아서 그대로 출력해주는 역할

chain={'query': RunnablePassthrough(), 'context': retrieval} | prompt | model | StrOutputParser()
# 만든 쿼리와 context를 prompt에 전달 -> model(gpt-4.1) 전달 -> StrOutputParser() 전달('String으로 결과를 받아보겠다'라는 의미)

chain.invoke(query)

"""
'질문에 대해 이야기해 줄게요! 이야기 속에서 요술 거울이 “왕비님도 아름답지만 백설공주가 더 아름답습니다.”라고 대답했어요. 또, “백설공주님이 천배는 더 아름답습니다.”라고도 했지요. 그래서 이야기에서는 백설공주가 더 아름답다고 나와 있답니다. 하지만 우리 모두는 각자만의 아름다움이 있어요! 너도, 나도, 백설공주도, 왕비도 모두 특별하고 소중하단다. 아름다움은 겉모습뿐만 아니라 마음에서도 나온다는 걸 꼭 기억해 줘!'
"""

# pdf 이야기 내용 바탕으로 물어보고 싶은 질문
chain.invoke('백설공주는 어디로 도망쳤나요?')
"""  '백설공주는 울면서 숲으로 도망쳤어요. 숲에는 새로운 친구들과 신나는 모험이 기다리고 있었답니다!' """

# 다른 예시
chain = prompt | model | StrOutputParser()

chain.invoke({'query': '난쟁이는 몇명인가요?', 'context': retrieval})
""" '난쟁이는 일곱 명이에요! 동화 속에서 난쟁이들은 언제나 힘을 합쳐서 멋진 모험을 떠나지요. 너도 언젠가 멋진 친구들과 함께 신나는 모험을 할 수 있을 거예요!'  """
