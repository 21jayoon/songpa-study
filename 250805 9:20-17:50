ì¢‹ì•„! ì•„ë˜ëŠ” `LangChain`ì„ ì´ìš©í•´ì„œ **LLM ì²´ì¸ (LLM Chain)** ì„ ë§Œë“œëŠ” ì˜ˆì œ ì½”ë“œì™€ ê° ë‹¨ê³„ì— ëŒ€í•œ **ìì„¸í•œ ì„¤ëª…**ì´ì•¼.
ë„ˆëŠ” ì´ ì½”ë“œë¥¼ í†µí•´ì„œ, â€œì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?â€ë¼ëŠ” ì§ˆë¬¸ì„ AIì—ê²Œ ë¬¼ì–´ë³´ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë°°ìš¸ ìˆ˜ ìˆì–´.
ì´ˆë³´ ê³ ë“±í•™ìƒì„ ëŒ€ìƒìœ¼ë¡œ ì‰½ê²Œ ì„¤ëª…í• ê²Œ!

---

### ğŸ”§ ì‚¬ìš© ë„êµ¬

* `PromptTemplate`: AIì—ê²Œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í• ì§€ í˜•ì‹ì„ ì •í•´ì£¼ëŠ” ë„êµ¬
* `LLM`: ì‹¤ì œë¡œ AI ëª¨ë¸ì´ ëŒ€ë‹µì„ ë§Œë“¤ì–´ë‚´ëŠ” ë¶€ë¶„
* `StrOutputParser`: AIê°€ ì¤€ ëŒ€ë‹µì„ ì‚¬ëŒì´ ë³´ê¸° ì‰½ê²Œ ë¬¸ìì—´ë¡œ ë°”ê¿”ì£¼ëŠ” ë„êµ¬

---

## âœ… ì „ì²´ ëª©í‘œ

> "ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?"ë¼ëŠ” ì§ˆë¬¸ì„ LLMì—ê²Œ ë¬¼ì–´ë³´ê³ , ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ì¶œë ¥í•˜ê¸°!

---

## ğŸ“¦ 1ë‹¨ê³„: PromptTemplate ë§Œë“¤ê¸°

```python
from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["question"],
    template="ì§ˆë¬¸: {question}\nAIì˜ ëŒ€ë‹µ:"
)
```

### ğŸ§‘â€ğŸ« ì„¤ëª…:

* `PromptTemplate`ì€ ì§ˆë¬¸ì„ ì–´ë–¤ **í˜•ì‹ìœ¼ë¡œ** AIì—ê²Œ ì¤„ì§€ ê²°ì •í•˜ëŠ” ë„êµ¬ì•¼.
* `input_variables=["question"]`: ì—¬ê¸°ì— ë‚˜ì¤‘ì— ìš°ë¦¬ê°€ ê¶ê¸ˆí•œ ì§ˆë¬¸ì„ ë„£ì„ ê±°ì•¼.
* `template`: ì‹¤ì œë¡œ AIê°€ ë³´ê²Œ ë  í…œí”Œë¦¿ì´ì•¼. ì—¬ê¸°ì„œ `{question}`ì€ ë‚˜ì¤‘ì— ì‹¤ì œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ë€” ë¶€ë¶„ì´ì•¼.
* ê²°ê³¼ì ìœ¼ë¡œ AIëŠ” ì´ëŸ° ì‹ìœ¼ë¡œ ì§ˆë¬¸ì„ ë°›ê²Œ ë¼:

  ```
  ì§ˆë¬¸: ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?
  AIì˜ ëŒ€ë‹µ:
  ```

---

## ğŸ¤– 2ë‹¨ê³„: LLM ëª¨ë¸ ì„ íƒí•˜ê¸°

```python
# ì´ê±° í‹€ë¦° ì½”ë“œ from langchain_community.llms import ChatOpenAI
# ì‹¤ì œ ì½”ë“œì—ì„  ì˜¤ë¥˜ ì•ˆ ë‚˜ê²Œ ê³ ì¹¨
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
```

### ğŸ§‘â€ğŸ« ì„¤ëª…:

* `ChatOpenAI`ëŠ” OpenAIì—ì„œ ë§Œë“  ëŒ€í™”í˜• AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê±°ì•¼.
* `model_name="gpt-3.5-turbo"`: ì–´ë–¤ ëª¨ë¸ì„ ì“¸ì§€ ì •í•´ì£¼ëŠ” ë¶€ë¶„. ì—¬ê¸°ì„œëŠ” GPT-3.5ë¥¼ ì‚¬ìš©í•´.
* `temperature=0.7`: ì°½ì˜ì„± ì •ë„ì•¼. ìˆ«ìê°€ í´ìˆ˜ë¡ ë” ììœ ë¡­ê³  ë‹¤ì–‘í•˜ê²Œ ëŒ€ë‹µí•´.

---

## ğŸ§¹ 3ë‹¨ê³„: OutputParser ì‚¬ìš©í•˜ê¸°

```python
from langchain_core.output_parsers import StrOutputParser

parser = StrOutputParser()
```

### ğŸ§‘â€ğŸ« ì„¤ëª…:

* LLMì´ ëŒ€ë‹µì„ í•´ì£¼ê¸´ í•˜ëŠ”ë°, ê·¸ ëŒ€ë‹µì´ ì‚¬ëŒì´ ë³´ê¸°ì—” ë³µì¡í•  ìˆ˜ ìˆì–´.
* `StrOutputParser()`ëŠ” AIê°€ ëŒ€ë‹µí•œ ë‚´ìš©ì„ **ë¬¸ìì—´ë¡œ ì •ë¦¬**í•´ì£¼ëŠ” ë„êµ¬ì•¼.
* ì¦‰, ë³´ê¸° ì¢‹ê²Œ ê¹”ë”í•˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ê±°ì§€!

---

## ğŸ”— 4ë‹¨ê³„: LLMChain ë§Œë“¤ê¸° + ì§ˆë¬¸í•˜ê¸°

```python
from langchain_core.runnables import RunnableSequence

chain = RunnableSequence(
    #steps=[
        prompt,  # 1ë‹¨ê³„: ì§ˆë¬¸ í˜•ì‹ ë§Œë“¤ê¸°
        llm,     # 2ë‹¨ê³„: AI ëª¨ë¸ì—ê²Œ ì „ë‹¬
        parser   # 3ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬í•˜ê¸°
    #] ì´ steps ë¶€ë¶„  í•„ìš” ì—†ì—ˆìŒ. ì˜¤íˆë ¤ ì˜¤ë¥˜ë‚¨.
    # ì‚­ì œí•˜ê³  RunnableSequence[prompt, llm, parser]ë¡œë§Œ ëŒë¦¬ë‹ˆ ì˜ ëŒì•„ê°
)

result = chain.invoke({"question": "ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?"})
print(result)
```

### ğŸ§‘â€ğŸ« ì„¤ëª…:

* `RunnableSequence`: ìœ„ì—ì„œ ë§Œë“  `prompt â†’ llm â†’ parser` ìˆœì„œë¥¼ ì—°ê²°í•´ì£¼ëŠ” ë„êµ¬ì•¼.
* `chain.invoke(...)`: ì‹¤ì œë¡œ ì§ˆë¬¸ì„ AIì—ê²Œ ë˜ì§€ê³ , ê²°ê³¼ë¥¼ ë°›ëŠ” ë¶€ë¶„ì´ì•¼.
* `print(result)`: ìµœì¢… ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥í•´ì¤˜!

---

## âœ… ì „ì²´ ì½”ë“œ ì •ë¦¬

```python
from langchain_core.prompts import PromptTemplate
from langchain_community.llms import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableSequence

# 1. Prompt ë§Œë“¤ê¸°
prompt = PromptTemplate(
    input_variables=["question"],
    template="ì§ˆë¬¸: {question}\nAIì˜ ëŒ€ë‹µ:"
)

# 2. LLM (AI ëª¨ë¸) ë¶ˆëŸ¬ì˜¤ê¸°
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)

# 3. OutputParser ì„¤ì •
parser = StrOutputParser()

# 4. ìˆœì„œëŒ€ë¡œ ì—°ê²°í•œ ì²´ì¸ ë§Œë“¤ê¸°
chain = RunnableSequence(
    steps=[
        prompt,
        llm,
        parser
    ]
)

# ì‹¤ì œ ì§ˆë¬¸ì„ ë˜ì§€ê³  ê²°ê³¼ ì¶œë ¥
result = chain.invoke({"question": "ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?"})
print(result)
```

---

## ğŸ“ ìš”ì•½

| ë‹¨ê³„                   | ì„¤ëª…                       |
| -------------------- | ------------------------ |
| 1ë‹¨ê³„ (PromptTemplate) | AIì—ê²Œ ì§ˆë¬¸ì„ ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ì¤„ì§€ ì •í•´ì¤Œ  |
| 2ë‹¨ê³„ (LLM)            | ì‹¤ì œë¡œ AIê°€ ìƒê°í•´ì„œ ëŒ€ë‹µí•¨         |
| 3ë‹¨ê³„ (OutputParser)   | AIì˜ ë³µì¡í•œ ì‘ë‹µì„ ì‚¬ëŒì´ ë³´ê¸° ì‰½ê²Œ ì •ë¦¬ |
| 4ë‹¨ê³„ (Chain)          | ìœ„ ë‹¨ê³„ë¥¼ ì°¨ë¡€ëŒ€ë¡œ ì‹¤í–‰í•´ì„œ ê²°ê³¼ ë„ì¶œ    |

---

# llm practice
### Chainì„ ì´ìš©í•œ Simple LLM
íë¦„: Prompt -> LLM -> OutputParser
1. Prompt
2. LLM
3. OutputParser

# 1. PromptTemplate
'''from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["question"],
    template="ì§ˆë¬¸: {question}\nAIì˜ ëŒ€ë‹µ:"
)
ë‚´ê°€ Gptë¡œ ì‘ì„±í•œ ë¶€ë¶„
'''
from langchain_core.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate([  # ë°°ì—´ì— íŠœí”Œì„ ì „ë‹¬í•¨
    ('system', 'ë„ˆëŠ” ì• ë‹ˆë©”ì´ì…˜ í¬ì¼“ëª¬ìŠ¤í„°ë¥¼ ì¢‹ì•„í•˜ëŠ” ì±—ë´‡ì´ì•¼. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í¬ì¼“ëª¬ìŠ¤í„° ìºë¦­í„° ëƒì˜¹ì´ì˜ ë§íˆ¬ë¡œ ëŒ€ë‹µí•´ì¤˜.'),
    ('user', '{question}') # ë³€ê²½ ê°€ëŠ¥í•œ ë³€ìˆ˜
])

# 2. Model
from langchain_openai import ChatOpenAI

'''llm = ChatOpenAI(
    model_name="gpt-3.5-turbo", 
    temperature=0.7
)'''
model = ChatOpenAI(
    model_name="gpt-4o",
    temperature=1
)

# 3. OutpurParser (StrOutputParser - langchain_core.output_parsers ì„í¬íŠ¸ í•„ìš”)
from langchain_core.output_parsers import StrOutputParser

# 3-1. ê°ì²´ ìƒì„±
parser = StrOutputParser()

# 3-2. ì•„ì›ƒí’‹ íŒŒì„œë¡œ ì²´ì¸ ì—°ê²°
# ì™œ Stringìœ¼ë¡œ ë³€ê²½? -> chainì—ì„œ ë‚˜ì˜¤ëŠ” ê°’ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜ë°›ê³ ì í•¨ -> StrOutputParser ì‚¬ìš©

# 4. Chain -> ì§ˆì˜
'''from langchain_core.runnables import RunnableSequence

chain = RunnableSequence(

        prompt,  # 1ë‹¨ê³„: ì§ˆë¬¸ í˜•ì‹ ë§Œë“¤ê¸°
        llm,     # 2ë‹¨ê³„: AI ëª¨ë¸ì—ê²Œ ì „ë‹¬
        parser   # 3ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬í•˜ê¸°
    
)'''
chain = prompt_template | model | parser

# question: ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?
result = chain.invoke({"question": "ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•´?"})
# ìœ„ì—ì„œ íŠœí”Œ í˜•íƒœë¡œ ì „ë‹¬ì„ í–ˆê¸° ë•Œë¬¸ì— question ë¶€ë¶„ì— dictionary í˜•íƒœë¡œ ì§ˆë¬¸ ì „ë‹¬
print(result)
"""1: gpt
í¬ì¼“ëª¬ì˜ ê°•í•¨ì€ ì¢…ë¥˜ë‚˜ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, ì „íˆ¬ë ¥ì´ ë†’ì€ í¬ì¼“ëª¬ìœ¼ë¡œëŠ” ë®¤ì¸ , ë ˆì§€ê¸°ê°€ìŠ¤, ë¼í‹°ì•„ìŠ¤ ë“±ì´ ìˆìŠµë‹ˆë‹¤.
í•˜ì§€ë§Œ í¬ì¼“ëª¬ ê²Œì„ì—ì„œëŠ” ì „ëµê³¼ ì¡°í•©ì´ ë” ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì— ë‹¨ìˆœíˆ ê°•í•œ í¬ì¼“ëª¬ì´ë¼ê³ ë§Œ ë§í•˜ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤.
"""

"""2
ìŒë¨¸... ì–´ë–¤ í¬ì¼“ëª¬ì´ ê°€ì¥ ê°•í•œì§€ëŠ” ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, ì•„ë§ˆë„ ë®¤ì¸ ê°€ ì•„ì£¼ ê°•í•˜ë‹¤ê³  í•  ìˆ˜ ìˆì„ ê±°ì•¼ì˜¹.
ì „ì„¤ì ì¸ í¬ì¼“ëª¬ì—, ì´ˆëŠ¥ë ¥ íƒ€ì…ì´ë¼ë‹ˆ ê°•ë ¥í•˜ì§€ ì•Šê² ëƒì˜¹? í•˜ì§€ë§Œ ëª¨ë“  í¬ì¼“ëª¬ì€ ê°ìì˜ ì¥ì ì´ ìˆìœ¼ë‹ˆê¹Œ, ìƒí™©ì— ë§ê²Œ ì „ëµì„ ì§œëŠ” ê²Œ ì¤‘ìš”í•˜ë‹µë‹ˆë‹¤ì˜¹!
"""



# Memory
# ì»¨íƒìŠ¤íŠ¸ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ ëª¨ë“ˆ, Langchainì˜ ë˜ë‹¤ë¥¸ í•µì‹¬
# ì´ì „ ì…ë ¥ì— ë‹µë³€í–ˆë˜ ê±¸ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•˜ê³  ì—°ì†ì ì¸ ì‘ë‹µì„ ê°€ëŠ¥ì¼€ í•¨

# RunnableWithMessageHistory

from langchain_core.chat_history import BaseChatMessageHistory
# BCMHëŠ” ìë°”ì˜ ì¶”ìƒí´ë˜ìŠ¤ì™€ ë™ì¼. ëŒ€í™”ë¥¼ ì €ì¥í•˜ëŠ” ê·œê²©ì´ë‚˜ ê·œì¹™ì„ ì €ì¥í•´ë†“ì€ ê²ƒ ë¿.

# class [className] ([ìƒì†ë°›ê³ ìí•˜ëŠ” ê°ì²´])
# ì¸ë©”ëª¨ë¦¬ ê¸°ì–µ ì €ì¥ì†Œ
class InMemoryHistory(BaseChatMessageHistory): 
    def __init__(self):  # self = Javaì˜ this
        self.messages = []  # InMemoryHistory = ëŒ€í™” ë©”ì„¸ì§€ ë‚´ì—­ì„ ì €ì¥í•˜ëŠ” ìš©ë„

    def add_messages(self, messages):
        self.messages.extend(messages)  # ì „ë‹¬ëœ ë¦¬ìŠ¤íŠ¸ ì•ˆì— ë©”ì„¸ì§€ë¥¼ í•˜ë‚˜ì”© ì¶”ê°€
        # addë‚˜ append ë§ê³  extend ì‚¬ìš©

    def clear(self):
        self.messages = []

    # ë¶€ê°€ì ì¸ ì„¤ëª…
    # classë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í–ˆì„ ë•Œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
    # ì¸ìŠ¤í„´ìŠ¤ í˜¸ì¶œí–ˆì„ ë•Œ ë™ì‘í•˜ëŠ” ì• ë¥¼ __repr__ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŒ
    def __repr__(self): 
        return str(self.messages)

store = {} # empty dictionary (Key(session ID) and Value(inmemoryhistory's object) needed)

# ì„¸ì…˜ ë‹¨ìœ„ë¡œ ê°ì²´ ìƒì„±(ì„¸ì…˜ ì•„ì´ë””ë¥¼ ì „ë‹¬ë°›ì•„ì„œ í•´ë‹¹ ì•„ì´ë””ì™€ ì¼ì¹˜í•˜ëŠ” ê²Œ ì €ì¥ì†Œì— ìˆë‹¤ë©´ ê·¸ê±¸ ë°˜í™˜)
def get_by_session_id(session_id):
    if session_id not in store:
        store[session_id] = InMemoryHistory()  # ì—†ëŠ” í‚¤ ê°’ì— ìƒˆ valueë¥¼ ë„£ìœ¼ë©´ ìƒˆë¡œìš´ í‚¤-ë²¨ë¥˜ê°€ ìƒê¸´ë‹¤.
    return store[session_id]

history_a = get_by_session_id('test')  # í˜¸ì¶œ
history_a  # []

history_a.add_messages(['hello','hi', 'how are you?'])  # message ì¶”ê°€
history_a.add_messages(['I am fine', 'what about you?'])
history_a  # ['hello', 'hi', 'how are you?', 'I am fine', 'what about you?']
